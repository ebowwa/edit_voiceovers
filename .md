```
take your time 

we want this to remain the exact same once done in terms of def name and output response

this is `video/process_video.py`
```
# breaks down the video, by importing the conversion, getting the video properties, extracting and analysizing the frames we can then build the collages
# we feed the model the collages with additional features
import cv2
from video.frame_rates.frame_rate_conversion import convert_frame_rate 
from video.frame_rates.video_properties import get_video_properties # video meta data and calculations
from video.frame_rates.frame_rate_analysis import extract_frames_from_video, analyze_frame_rate_changes # extracting frames and analysis for changes

def process_video(video_file_path, target_frame_rate, frame_selection_strategy=None):
    """
    Processes a video file to adjust its frame rate and get its properties.

    Parameters:
    video_file_path (str): The path to the video file.
    target_frame_rate (int): The target frame rate to convert the video to.

    Returns:
    dict: A dictionary containing the video properties and the adjusted frame rate.
    """
    # Get video properties
    video_props = get_video_properties(video_file_path)
    print(video_props)

    # Extract frames from the video using the function from the imported script
    frames = extract_frames_from_video(video_file_path)

    # New logic for flexible frame selection
    selected_frames = []
    if frame_selection_strategy:
        for i, frame in enumerate(frames):
            # Example: frame_selection_strategy could analyze frame content or use simple index-based selection
            if frame_selection_strategy(i, frame):
                selected_frames.append(frame)
    else:
        # Default behavior: select all frames or adjust based on target_frame_rate
        selected_frames = convert_frame_rate(frames, target_frame_rate, video_props['Original Frame Rate'])
    
    # The rest of the function, including frame rate analysis, remains unchanged.
    frame_rate_analysis = analyze_frame_rate_changes(video_file_path)
    
    return {
        'Video Properties': video_props,
        'Adjusted Frames': selected_frames,  # Use the selected frames instead of all adjusted frames
        'Frame Rate Analysis': frame_rate_analysis,
    }

# Example usage
if __name__ == "__main__":
    video_file_path = "public/AdobeStock_607123108_Video_HD_Preview.mov"
    # Get video properties
    video_props = get_video_properties(video_file_path)

    # Calculate the target frame rate based on the video's original frame rate and total frames
    target_fps = int(video_props['Frame Count'] / video_props['Video Duration'])

    # display 1 frame per second + for the uploaded video 3-4 min max run


    # Process the video with the calculated target frame rate
    processed_video = process_video(video_file_path, target_fps)
    print(processed_video)
```

we need to write a new modular importable script that can be imported to this  `video/process_video.py` script, this script should not change the response but change some of the actions of the process_video function.

ideally we need the following function also applied to the chosen frame rates. `video/process_video.py` should import and use this `select_frames_based_on_criteria` function to handle frame rates chosen for the process_video return


./video/frame_rates/frame_criteria.py
```
def select_frames_based_on_criteria(frame_index, frame, fps, video_duration, user_criteria="dynamic"):
    """
    Selects frames based on the video duration and specified criteria.
    
    Parameters:
    - frame_index (int): The index of the current frame.
    - frame (ndarray): The current frame.
    - fps (int): The frames per second of the video.
    - video_duration (float): The duration of the video in seconds.
    - user_criteria (str or dict): The criteria for frame selection. Can be a predefined string ("one_per_second",
      "three_per_second") or a more complex dict for custom strategies.
    
    Returns:
    bool: True if the frame should be selected, False otherwise.
    """
    # Dynamically adjust selection based on video duration
    if user_criteria == "dynamic":
        if video_duration <= 60:  # Short videos (up to 1 min)
            interval = fps  # One frame per second
        elif video_duration <= 1800:  # Medium videos (up to 30 mins)
            interval = fps * 5  # One frame every 5 seconds
        else:  # Long videos (more than 30 mins)
            interval = fps * 30  # One frame every 30 seconds
        return frame_index % interval == 0
    elif isinstance(user_criteria, dict):
        # Custom criteria logic here, for example:
        if user_criteria.get("type") == "fixed_interval":
            interval = user_criteria.get("interval", 1) * fps
            return frame_index % interval == 0
        # Additional custom criteria can be implemented here
    else:
        # Fallback to simple predefined criteria
        if user_criteria == "one_per_second":
            return frame_index % fps == 0
        elif user_criteria == "three_per_second":
            return frame_index % (fps // 3) == 0
        # Other predefined criteria can be added here

    return False
```
def calculate_tokens_per_second(speech_rate_wpm=150, avg_word_length=5):
    """
    Calculate the tokens (characters) generated per second based on speech rate.
    
    :param speech_rate_wpm: Speech rate in words per minute.
    :param avg_word_length: Average word length in characters.
    :return: Tokens (characters) per second.
    """
    tokens_per_minute = speech_rate_wpm * avg_word_length
    tokens_per_second = tokens_per_minute / 60
    return tokens_per_second
import cv2
import numpy as np
# Adaptive frame selection based on video activity and LLM processing capabilities
def adaptive_frame_selection(significant_frames, video_fps, tokens_per_sec, total_duration):
    frames_per_token = video_fps / tokens_per_sec
    total_frames = video_fps * total_duration
    average_change_rate = len(significant_frames) / total_frames

    interval = int(frames_per_token / average_change_rate)
    interval = max(1, interval)  # Ensure at least one frame is selected

    selected_frames = significant_frames[::interval]
    return selected_frames

# Example usage
selected_frames = adaptive_frame_selection(range(1, 642), 30, 12.5, 7)
print(f"Selected frames for LLM processing: {selected_frames}")

each 100 tokens equal one request allowance therefore one collage aka 6 frames
try to not refactor and REINTRODUCE RATHER just quickly fix and or patch up
```
first identify the workflow and calculations to the mentioned about the framerates and dynamic selection 