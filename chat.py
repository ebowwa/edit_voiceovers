from gemini.auth_gemini import get_api_key
from gemini.model_setup_chat import configure_genai

# Function for generating a chat response using Gemini API
def chat_completion(user_input, prompt):
    # Authenticate and get the API key
    api_key = get_api_key()
    # Configure the Gemini model
    model = configure_genai(api_key)
    # Generate content based on the user input and the prompt
    response = model.generate_content([prompt, user_input])
    
    # Check if the response is simple text or multi-part
    if len(response.parts) == 1:
        # If simple text, return as is
        return response.text
    else:
        # If multi-part, concatenate the text parts
        return ''.join([part.text for part in response.parts])

# Function to get the prompt feedback from the response
def get_prompt_feedback(response):
    # Returns any feedback related to the prompt, like safety concerns
    return response.prompt_feedback

# Function to get response candidates from the response
#def get_response_candidates(response):
    # Returns different response options generated by the model
#   return response.candidates

# Function to handle incomplete iteration errors
def handle_incomplete_iteration(response):
    # Handles errors when streaming responses are not fully iterated
    try:
        return response.text
    except IncompleteIterationError as e:
        # Returns the error message if there's an incomplete iteration
        return str(e)

# Example usage
user_input = "What is a tree?"
prompt = "Please explain:"
chat_response = chat_completion(user_input, prompt)
print(chat_response)
# To use this code:
# 1. Call 'chat_completion' with the user's input and your prompt.
# 2. Optionally, use 'get_prompt_feedback' and 'get_response_candidates' to get more insights from the response.
# 3. If using streaming responses, use 'handle_incomplete_iteration' to manage potential iteration errors.

